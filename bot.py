
import logging
import os
import openai
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes
from dotenv import load_dotenv
from datetime import datetime
from logic.route_calc import calculate_eta

context_history = []
MAX_TURNS = 6

load_dotenv()
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
openai.api_key = OPENAI_API_KEY

logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO)

try:
    with open("prompt.txt", "r", encoding="utf-8") as f:
        SYSTEM_PROMPT = f.read()
except FileNotFoundError:
    SYSTEM_PROMPT = "–¢—ã ‚Äî –ú–∞–∫—Å. –î–∏—Å–ø–µ—Ç—á–µ—Ä, –ø–æ–º–æ—â–Ω–∏–∫ –∏ –Ω–∞–ø–∞—Ä–Ω–∏–∫ –¥–∞–ª—å–Ω–æ–±–æ–π—â–∏–∫–∞. –í—Å—ë –ø–æ-—á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏."

def load_relevant_knowledge(user_input: str) -> str:
    keywords_map = {
        "–æ—Ç–¥—ã—Ö": "Rezim_RTO.md",
        "–ø–∞—É–∑": "Rezim_RTO.md",
        "—Å–º–µ–Ω": "Rezim_RTO.md",
        "—Ç–∞—Ö–æ–≥—Ä–∞—Ñ": "4_tahograf_i_karty.md",
        "–∫–∞—Ä—Ç–∞": "4_tahograf_i_karty.md",
        "–ø–æ–µ–∑–¥": "ferry_routes.md",
        "–ø–∞—Ä–æ–º": "ferry_routes.md",
        "—Ü–º—Ä": "CMR.md",
        "–¥–æ–∫—É–º–µ–Ω—Ç": "CMR.md",
        "–∫–æ–º—Ñ–æ—Ä—Ç": "11_komfort_i_byt.md",
        "–ø–∏—Ç–∞–Ω–∏–µ": "12_pitanie_i_energiya.md"
    }

    selected_files = set()
    lowered = user_input.lower()
    for keyword, filename in keywords_map.items():
        if keyword in lowered:
            selected_files.add(filename)

    texts = []
    for filename in sorted(selected_files):
        path = os.path.join("knowledge", filename)
        if os.path.exists(path):
            with open(path, "r", encoding="utf-8") as f:
                content = f.read().strip()
                if content:
                    texts.append(f"üìò {filename}:
{content}
")
    return "\n".join(texts) or ""

async def ask_gpt(messages):
    try:
        return openai.ChatCompletion.create(model="gpt-4o", messages=messages)
    except Exception as e:
        logging.warning(f"GPT-4o –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, fallback: {e}")
        try:
            return openai.ChatCompletion.create(model="gpt-3.5-turbo-1106", messages=messages)
        except Exception as e2:
            logging.error(f"GPT-3.5 —Ç–æ–∂–µ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e2}")
            return None

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–ó–¥–æ—Ä–æ–≤–∞, —è ‚Äî –ú–∞–∫—Å. –î–∏—Å–ø–µ—Ç—á–µ—Ä, –¥—Ä—É–≥ –∏ –Ω–∞–≤–∏–≥–∞—Ç–æ—Ä –ø–æ —Ä–µ–π—Å—É. –ü–∏—à–∏ ‚Äî –≤–º–µ—Å—Ç–µ —Ä–∞–∑–±–µ—Ä—ë–º—Å—è!")

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_input = update.message.text.strip()
    if not user_input:
        await update.message.reply_text("–ß–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å?")
        return

    lowered = user_input.lower()

    if any(word in lowered for word in ["—Ä–∞—Å—á–∏—Ç–∞–π", "–º–∞—Ä—à—Ä—É—Ç", "–∑–∞–≥—Ä—É–∑–∫–∞", "–≤—ã–≥—Ä—É–∑–∫–∞", "–∫–º", "–≤—Ä–µ–º—è"]):
        try:
            segments = [
                {"type": "drive", "distance_km": 240},
                {"type": "wait", "duration_min": 60, "note": "–ó–∞–≥—Ä—É–∑–∫–∞"},
                {"type": "drive", "distance_km": 600},
                {"type": "pause", "duration_min": 30, "note": "–ó–∞–ø—Ä–∞–≤–∫–∞"},
                {"type": "drive", "distance_km": 1050}
            ]
            start_time = datetime.strptime("2025-06-06 06:00", "%Y-%m-%d %H:%M")
            result, total_km = calculate_eta(start_time, segments)

            reply_lines = ["üõ£Ô∏è –ì—Ä–∞—Ñ–∏–∫ –º–∞—Ä—à—Ä—É—Ç–∞:
"]
            for e in result:
                reply_lines.append(f"üïí {e['start'].strftime('%d.%m %H:%M')} ‚Üí {e['end'].strftime('%H:%M')} | {e['action']}")
            reply_lines.append(f"\nüìè –í—Å–µ–≥–æ: {total_km} –∫–º")
            await update.message.reply_text("\n".join(reply_lines))
            return
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á—ë—Ç–∞ –º–∞—Ä—à—Ä—É—Ç–∞: {e}")
            await update.message.reply_text("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á—ë—Ç–µ –º–∞—Ä—à—Ä—É—Ç–∞.")
            return

    context_history.append({"role": "user", "content": user_input})
    messages = [{"role": "system", "content": SYSTEM_PROMPT}]
    kb_snippet = load_relevant_knowledge(user_input)
    if kb_snippet:
        messages.append({"role": "system", "content": "üìö –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π:\n" + kb_snippet})
    messages += context_history[-MAX_TURNS:]

    response = await ask_gpt(messages)
    if response:
        reply = response.choices[0].message.content.strip()
        context_history.append({"role": "assistant", "content": reply})
        await update.message.reply_text(reply)
    else:
        await update.message.reply_text("‚ùå –ú–∞–∫—Å –Ω–µ —Å–º–æ–≥ –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç. –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ.")

if __name__ == '__main__':
    app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    app.run_polling()
